{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample text data\n",
        "text = \"this is a test\"\n",
        "words = text.split()\n",
        "\n",
        "# Create a vocabulary\n",
        "vocab = sorted(list(set(words)))\n",
        "word_to_index = {word: index for index, word in enumerate(vocab)}\n",
        "index_to_word = {index: word for index, word in enumerate(vocab)}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Create input and target sequences\n",
        "input_sequences = []\n",
        "target_sequences = []\n",
        "for i in range(len(words) - 3):\n",
        "    input_sequences.append([word_to_index[word] for word in words[i:i+3]])\n",
        "    target_sequences.append(word_to_index[words[i+3]])\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(input_sequences)\n",
        "y = np.array(target_sequences)\n",
        "\n",
        "# Define RNN model parameters\n",
        "input_size = vocab_size\n",
        "hidden_size = 4\n",
        "output_size = vocab_size\n",
        "\n",
        "np.random.seed(42)\n",
        "Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
        "Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "Why = np.random.randn(output_size, hidden_size) * 0.01\n",
        "bh = np.zeros((hidden_size, 1))\n",
        "by = np.zeros((output_size, 1))\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / np.sum(e_x)\n",
        "\n",
        "def rnn_step(x, h_prev):\n",
        "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h_prev) + bh)\n",
        "    y = np.dot(Why, h) + by\n",
        "    return h, y\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    h = np.zeros((hidden_size, 1))\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        hs = {}  # to store hidden states\n",
        "        hs[-1] = np.copy(h)\n",
        "\n",
        "        # Forward\n",
        "        for t in range(3):\n",
        "            inputs = np.zeros((vocab_size, 1))\n",
        "            inputs[X[i][t]] = 1\n",
        "            h, y_pred = rnn_step(inputs, h)\n",
        "            hs[t] = h\n",
        "\n",
        "        probs = softmax(y_pred)\n",
        "        target_index = y[i]\n",
        "        loss += -np.log(probs[target_index])\n",
        "\n",
        "        # Backward (only simple update)\n",
        "        dy = probs\n",
        "        dy[target_index] -= 1\n",
        "\n",
        "        # Gradients\n",
        "        dWhy = np.dot(dy, hs[2].T)\n",
        "        dby = dy\n",
        "\n",
        "        dh = np.dot(Why.T, dy) * (1 - hs[2] ** 2)\n",
        "\n",
        "        dWxh = np.dot(dh, np.zeros((vocab_size, 1)).T)\n",
        "        dWhh = np.dot(dh, hs[1].T)\n",
        "        dbh = dh\n",
        "\n",
        "        # Update parameters\n",
        "        Why -= learning_rate * dWhy\n",
        "        by -= learning_rate * dby\n",
        "        Whh -= learning_rate * dWhh\n",
        "        bh -= learning_rate * dbh\n",
        "\n",
        "    if (epoch+1) % 10 == 0 or epoch == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Make prediction\n",
        "h = np.zeros((hidden_size, 1))\n",
        "inputs = np.zeros((vocab_size, 1))\n",
        "inputs[word_to_index['this']] = 1\n",
        "h, _ = rnn_step(inputs, h)\n",
        "\n",
        "inputs = np.zeros((vocab_size, 1))\n",
        "inputs[word_to_index['is']] = 1\n",
        "h, _ = rnn_step(inputs, h)\n",
        "\n",
        "inputs = np.zeros((vocab_size, 1))\n",
        "inputs[word_to_index['a']] = 1\n",
        "h, y_pred = rnn_step(inputs, h)\n",
        "\n",
        "predicted_index = np.argmax(softmax(y_pred))\n",
        "predicted_word = index_to_word[predicted_index]\n",
        "print(f\"\\nPredicted word: {predicted_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6hXmInrLQcI",
        "outputId": "8bd3baaa-2053-4657-f778-417442e98370"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.3863\n",
            "Epoch 10, Loss: 0.8503\n",
            "Epoch 20, Loss: 0.5263\n",
            "Epoch 30, Loss: 0.3577\n",
            "Epoch 40, Loss: 0.2628\n",
            "Epoch 50, Loss: 0.2045\n",
            "Epoch 60, Loss: 0.1658\n",
            "Epoch 70, Loss: 0.1385\n",
            "Epoch 80, Loss: 0.1185\n",
            "Epoch 90, Loss: 0.1032\n",
            "Epoch 100, Loss: 0.0911\n",
            "\n",
            "Predicted word: test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eIsHGzIkR4ny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}